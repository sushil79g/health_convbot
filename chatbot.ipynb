{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushil79g/health_convbot/blob/master/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lp8zl2ZVXpg",
        "colab_type": "code",
        "outputId": "8bb58da6-05c8-4b6f-dbc9-f49792359754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdMTyrJQVKgO",
        "colab_type": "code",
        "outputId": "7d54cc01-57df-462d-b8ba-ffd8ab5705d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "base_folder = 'drive/My Drive/dataset/'\n",
        "!pip install contractions\n",
        "!pip install textsearch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/2a/ba0a3812e2a1de2cc4ee0ded0bdb750a7cef1631c13c78a4fc4ab042adec/contractions-0.0.21-py2.py3-none-any.whl\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.21\n",
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick (from textsearch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 8.9MB/s \n",
            "\u001b[?25hCollecting Unidecode (from textsearch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 39.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, Unidecode, textsearch\n",
            "Successfully installed Unidecode-1.1.1 pyahocorasick-1.4.0 textsearch-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxpx4dFFVI_7",
        "colab_type": "code",
        "outputId": "3f27e928-e725-4f3e-8f60-b1790f6b7a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "import re\n",
        "import pandas as pd\n",
        "import contractions\n",
        "\n",
        "contractions.add(\"c'mon\", 'come on')\n",
        "\n",
        "file = pd.read_csv(base_folder + 'friends_chat.txt',sep='\\t')\n",
        "lines = file['line']\n",
        "\n",
        "print('Initial chats')\n",
        "for i in range(10):\n",
        "    print(lines[i])\n",
        "    \n",
        "def cleanchat(line):\n",
        "    #to convert text to lower case\n",
        "    line = line.lower()\n",
        "    #to remove ending EOL\n",
        "    line = re.sub(r'\\n','',line) \n",
        "    #re-format punctuations\n",
        "    line = re.sub(r\"[-()]\", \"\", line)\n",
        "    line = re.sub(r\"\\.\", \" .\", line)\n",
        "    line = re.sub(r\"\\!\", \" !\", line)\n",
        "    line = re.sub(r\"\\?\", \" ?\", line)\n",
        "    line = re.sub(r\"\\,\", \" ,\", line)\n",
        "    \n",
        "    #string replacement\n",
        "    line = re.sub(r\"i'm\", \"i am\", line)\n",
        "    line = re.sub(r\"he's\", \"he is\", line)\n",
        "    line = re.sub(r\"she's\", \"she is\", line)\n",
        "    line = re.sub(r\"it's\", \"it is\", line)\n",
        "    line = re.sub(r\"that's\", \"that is\", line)\n",
        "    line = re.sub(r\"what's\", \"that is\", line)\n",
        "    line = re.sub(r\"\\'ll\", \" will\", line)\n",
        "    line = re.sub(r\"\\'re\", \" are\", line)\n",
        "    line = re.sub(r\"won't\", \"will not\", line)\n",
        "    line = re.sub(r\"can't\", \"cannot\", line)\n",
        "    line = re.sub(r\"n't\", \" not\", line)\n",
        "    line = re.sub(r\"n'\", \"ng\", line)\n",
        "    line = re.sub(r\"ohh\", \"oh\", line)\n",
        "    line = re.sub(r\"ohhh\", \"oh\", line)\n",
        "    line = re.sub(r\"ohhhh\", \"oh\", line)\n",
        "    line = re.sub(r\"ohhhhh\", \"oh\", line)\n",
        "    line = re.sub(r\"ohhhhhh\", \"oh\", line)\n",
        "    line = re.sub(r\"ahh\", \"ah\", line)\n",
        "    \n",
        "    return line\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial chats\n",
            "There's nothing to tell! He's just some guy I work with!\n",
            "C'mon, you're going out with the guy! There's gotta be something wrong with him!\n",
            "Alright Joey, be nice. So does he have a hump? A hump and a hairpiece?\n",
            "Wait, does he eat chalk?\n",
            "Just, 'cause, I don't want her to go through what I went through with Carl- oh!\n",
            "Okay, everybody relax. This is not even a date. It's just two people going out to dinner and not having sex.\n",
            "Sounds like a date to me.\n",
            "Alright, so I'm back in high school, I'm standing in the middle of the cafeteria, and I realize I am totally naked.\n",
            "Oh, yeah. Had that dream.\n",
            "Then I look down, and I realize there's a phone... there.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOyc5cEHVKed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbXIT1rpVJAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(x):\n",
        "    clean = cleanchat(x)\n",
        "    processed = contractions.fix(clean)\n",
        "    return processed\n",
        "\n",
        "file['processed_text'] = file['line'].apply(preprocess)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo0PtzYBVJAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def length(x):\n",
        "    return len(x.split())\n",
        "file['length'] = file['line'].apply(length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XylRPRXcVJAP",
        "colab_type": "code",
        "outputId": "f4d12a5b-dd3f-4b54-c8ba-2c3721c1583a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "file['length'].describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    60849.000000\n",
              "mean        10.161416\n",
              "std         10.438841\n",
              "min          1.000000\n",
              "25%          3.000000\n",
              "50%          7.000000\n",
              "75%         14.000000\n",
              "max        195.000000\n",
              "Name: length, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-bjqFQQVJAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_WORD_LENGTH = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIkr4bR9VJAa",
        "colab_type": "code",
        "outputId": "dd529f4b-0edc-4020-a2c4-58f729c92c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "file.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>scene_id</th>\n",
              "      <th>person</th>\n",
              "      <th>gender</th>\n",
              "      <th>original_line</th>\n",
              "      <th>line</th>\n",
              "      <th>metadata</th>\n",
              "      <th>filename</th>\n",
              "      <th>processed_text</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>MONICA</td>\n",
              "      <td>F</td>\n",
              "      <td>Monica: There's nothing to tell! He's just som...</td>\n",
              "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
              "      <td>There_EX 's_VBZ nothing_PN1 to_TO tell_VVI !_!...</td>\n",
              "      <td>0101.txt</td>\n",
              "      <td>there is nothing to tell ! he is just some guy...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>JOEY</td>\n",
              "      <td>M</td>\n",
              "      <td>Joey: C'mon, you're going out with the guy! Th...</td>\n",
              "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
              "      <td>C'm_VV0 on_RP you_PPY 're_VBR going_VVG out_RP...</td>\n",
              "      <td>0101.txt</td>\n",
              "      <td>come on , you are going out with the guy ! the...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "      <td>CHANDLER</td>\n",
              "      <td>M</td>\n",
              "      <td>Chandler: All right Joey, be nice.  So does he...</td>\n",
              "      <td>Alright Joey, be nice. So does he have a hump?...</td>\n",
              "      <td>All_RR21 right_RR22 Joey_NP1 be_VBI nice_JJ ._...</td>\n",
              "      <td>0101.txt</td>\n",
              "      <td>alright joey , be nice . so does he have a hum...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>301</td>\n",
              "      <td>1</td>\n",
              "      <td>PHOEBE</td>\n",
              "      <td>F</td>\n",
              "      <td>Phoebe: Wait, does he eat chalk?</td>\n",
              "      <td>Wait, does he eat chalk?</td>\n",
              "      <td>Wait_VV0 does_VDZ he_PPHS1 eat_VVI chalk_NN1 ?_?</td>\n",
              "      <td>0101.txt</td>\n",
              "      <td>wait , does he eat chalk ?</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>401</td>\n",
              "      <td>1</td>\n",
              "      <td>PHOEBE</td>\n",
              "      <td>F</td>\n",
              "      <td>Phoebe: Just, 'cause, I don't want her to go t...</td>\n",
              "      <td>Just, 'cause, I don't want her to go through w...</td>\n",
              "      <td>Just_RR 'cause_CS I_PPIS1 do_VD0 n't_XX want_V...</td>\n",
              "      <td>0101.txt</td>\n",
              "      <td>just , because , i do not want her to go throu...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id scene_id  ...                                     processed_text length\n",
              "0    1        1  ...  there is nothing to tell ! he is just some guy...     11\n",
              "1  101        1  ...  come on , you are going out with the guy ! the...     14\n",
              "2  201        1  ...  alright joey , be nice . so does he have a hum...     15\n",
              "3  301        1  ...                         wait , does he eat chalk ?      5\n",
              "4  401        1  ...  just , because , i do not want her to go throu...     16\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3Vl5UZxVJAh",
        "colab_type": "code",
        "outputId": "00c21134-5d1e-424b-b47f-9b01612bb8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "file.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                0\n",
              "scene_id          0\n",
              "person            0\n",
              "gender            0\n",
              "original_line     0\n",
              "line              0\n",
              "metadata          0\n",
              "filename          0\n",
              "processed_text    0\n",
              "length            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luxTNKJRVJAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_dataframe = file[['person','processed_text']]\n",
        "remove_index = []\n",
        "chat_pair = []\n",
        "i = 0\n",
        "while i <= (len(temp_dataframe)-2):\n",
        "    raw_i = i\n",
        "    \n",
        "    while True:\n",
        "#         print(raw_i,i, i+1)\n",
        "        if temp_dataframe.iloc[i+1]['person'] == temp_dataframe.iloc[i]['person']:\n",
        "            temp_dataframe.iloc[raw_i]['processed_text'] += ','+ temp_dataframe.iloc[i+1]['processed_text']\n",
        "            chat_pair.append([temp_dataframe.iloc[raw_i]['processed_text'], temp_dataframe.iloc[raw_i+1]['processed_text']])\n",
        "            remove_index.append(i+1)\n",
        "        else:\n",
        "            break\n",
        "        i = i+1\n",
        "        \n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1c0NB2GVJAs",
        "colab_type": "code",
        "outputId": "2defc650-24ae-4276-f57a-59dc5f162943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "temp_dataframe.drop(remove_index, inplace=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  errors=errors)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euCMB7vWVJAz",
        "colab_type": "code",
        "outputId": "d5e10fd5-fb74-4fe6-c6de-1d8c72a0bb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "temp_dataframe.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MONICA</td>\n",
              "      <td>there is nothing to tell ! he is just some guy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JOEY</td>\n",
              "      <td>come on , you are going out with the guy ! the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CHANDLER</td>\n",
              "      <td>alright joey , be nice . so does he have a hum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PHOEBE</td>\n",
              "      <td>wait , does he eat chalk ?,just , because , i ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MONICA</td>\n",
              "      <td>okay , everybody relax . this is not even a da...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     person                                     processed_text\n",
              "0    MONICA  there is nothing to tell ! he is just some guy...\n",
              "1      JOEY  come on , you are going out with the guy ! the...\n",
              "2  CHANDLER  alright joey , be nice . so does he have a hum...\n",
              "3    PHOEBE  wait , does he eat chalk ?,just , because , i ...\n",
              "5    MONICA  okay , everybody relax . this is not even a da..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jy1YspFVJA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# contractions.add(\"c'mon\", 'come on')\n",
        "list_of_word = list(temp_dataframe['processed_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS05rheOVJA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = ' '.join(list_of_word).split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l2Rde4ZTc9R",
        "colab_type": "code",
        "outputId": "993eb62c-ce41-451a-e910-e9bfb0ce6c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(words)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "836085"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs_AsvdrVJBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "wordcount = Counter(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzgce2RwVJBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab= set(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnC1lraZPnAG",
        "colab_type": "code",
        "outputId": "c32ea1ba-3938-4b24-841f-053b1e0580c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17828"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGS681T_VJBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_threshold = []\n",
        "for word in vocab:\n",
        "    if wordcount[word] >=3:\n",
        "        word_threshold.append(word)\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb_fRhb-VJBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2ind ={{word, index} for word,index in enumerate(list(word_threshold))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_Iari2QVJBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2index = {}\n",
        "index2word = {}\n",
        "for index,word in enumerate(word_threshold):\n",
        "    word2index.update({word:index})\n",
        "    index2word.update({index:word})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqyGrls5VJBd",
        "colab_type": "code",
        "outputId": "209294a3-73bf-4262-dd28-c609d98b37d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pprint import pprint\n",
        "# pprint('total word in vocab',len(word_threshold))\n",
        "len(word_threshold)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PUIhn2pVJBk",
        "colab_type": "code",
        "outputId": "3ea85af3-63c2-4bb8-896d-927a82a25c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(word2index.keys()))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wfrp3uwVJBr",
        "colab_type": "code",
        "outputId": "7307c6ee-92f7-442a-aa83-ac82600083fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "chat_pair[1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sounds like a date to me .,alright , so i am back in high school , i am standing in the middle of the cafeteria , and i realize i am totally naked .',\n",
              " 'alright , so i am back in high school , i am standing in the middle of the cafeteria , and i realize i am totally naked .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7JNQXCUVJB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_max_length(sentences):\n",
        "    whole_sentence = []\n",
        "    for sentence in sentences:\n",
        "        sentence_remove = []\n",
        "        for word in sentence.split():\n",
        "            if word in word2index.keys():\n",
        "                sentence_remove.append(word)\n",
        "        whole_sentence.append(' '.join(sentence_remove))\n",
        "    return whole_sentence, max([len(sent) for sent in whole_sentence])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1QjtGO5VJCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whole_sentence, max_length = find_max_length(list_of_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qnk6NLAVJCI",
        "colab_type": "code",
        "outputId": "81828e52-3f3e-4911-8952-fd8a2626ba04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "length = []\n",
        "for sent in whole_sentence:\n",
        "    try:\n",
        "        len_ = len(sent.split())\n",
        "        length.append(len_)\n",
        "        if len_ == 259:\n",
        "            print(sent)    \n",
        "    except:\n",
        "        print(sent)\n",
        "max_length = max(length)\n",
        "max_length"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "okay it is time for the toast ! umm now now , i know that ross usually gives the toast , but this year i am going to do it .,no , no it is going to be great . really ! mom , dad , when i got married , one of the things that made me sure i could do it was the amazing example the two of you set for me . for that and so many other things i want to say thank you . i know i probably do not say it enough , but i love you . when i look around this room , i am by the thought of those who could not be here with us . nana , my beloved grandmother who would so want to be here , but she cannot because she is dead . as is our dog chichi . i mean look how cute she is . . was . do me a favor and pass this to my parents . remember she is dead . okay , her and nana , gone . wow ! hey does anybody remember when had to say goodbye to her children in terms of ? did not see that ? no movie fans ? ! you want to hear something sad ? the other day i was watching 60 minutes these in , who have been so , they were of love . you people are made of stone ! here's to mom and dad ! whatever !\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEiK_UvrYleK",
        "colab_type": "code",
        "outputId": "548b5621-861a-4f87-e69c-cea67a45507c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# EOS_token = -1\n",
        "# def make_equal_length(total_tensor):\n",
        "#     max_length = max([len(sent) for sent in total_tensor])\n",
        "#     for sent in total_tensor:\n",
        "#         if len(sent) < max_length:\n",
        "            \n",
        "    \n",
        "# def input_process(input_data, word2index):\n",
        "#     total_tensor = []\n",
        "#     max_input_length = max([len(sent.split()) for sent in input_data])\n",
        "#     for input_sent in input_data:\n",
        "#         tensor = [0] * max_input_length\n",
        "#         tensor = [tensor.insert() for index,word in enumerate(input_sent)] + [EOS_token]\n",
        "#         total_tensor.append(tensor)\n",
        "#     format_input = make_equal_length(total_tensor)\n",
        "    \n",
        "\n",
        "# def prepare_batch(batches_group, word2index, index2word):\n",
        "#     input_data = [batch[0] for batch in batches_group]\n",
        "#     output_data = [batch[1] for batch in bathces]\n",
        "#     length = max( len(sent.split()) for sent in input_data)\n",
        "#     input_processed = input_process(input_data, word2index)\n",
        "\n",
        "\n",
        "# small_batch = 5\n",
        "# batches_group = [random.choice(chat_pair) for _num in range(small_batch)]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-2404ba8fc5a6>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    def input_process(input_data, word2index):\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKGoy75UY2LZ",
        "colab_type": "code",
        "outputId": "6874f52b-7f2c-4f8c-98f0-b43f9de69426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import itertools\n",
        "\n",
        "EOS_token = -1\n",
        "PAD_token = 0\n",
        "def indexesFromSentence(word2index, sentence):\n",
        "#     print(sentence)\n",
        "    listdata = []\n",
        "    for word in sentence.split():\n",
        "        try:\n",
        "            listdata.append(word2index[word])\n",
        "        except:\n",
        "            pass\n",
        "    return_list = listdata + [EOS_token]\n",
        "    return return_list\n",
        "\n",
        "\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Returns padded input sequence tensor and lengths\n",
        "def inputVar(l, word2index):\n",
        "    indexes_batch = [indexesFromSentence(word2index, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "def outputVar(l, word2index):\n",
        "    indexes_batch = [indexesFromSentence(word2index, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.ByteTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(word2index, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, word2index)\n",
        "    output, mask, max_target_len = outputVar(output_batch, word2index)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n",
        "\n",
        "# Example for validation\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(word2index, [random.choice(chat_pair) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"max_target_len:\", max_target_len)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_variable: tensor([[ 910, 5685,  393, 5080, 5685],\n",
            "        [1643, 1352, 5685, 3318, 2724],\n",
            "        [1643, 5024, 5824, 6343, 1662],\n",
            "        [1643, 1563, 5589,  662, 6260],\n",
            "        [1905, 3720, 4170, 1402, 2618],\n",
            "        [ 662, 3961,  662, 5685, 6311],\n",
            "        [1632, 1643, 3565, 5350, 1761],\n",
            "        [ 662, 1643, 4170, 3720, 1643],\n",
            "        [1974, 1643, 3355,  662,   49],\n",
            "        [ 662,   37, 4162, 3814, 5024],\n",
            "        [ 910, 1643, 2542,  662, 2618],\n",
            "        [1643, 1643, 5126, 3814, 6705],\n",
            "        [1643, 1643, 4455, 1883,   -1],\n",
            "        [1643, 1643, 4770,  662,    0],\n",
            "        [2715,   37,  347, 6469,    0],\n",
            "        [5685, 1643, 5797, 3720,    0],\n",
            "        [5824, 4326, 3016, 1590,    0],\n",
            "        [3802, 1636, 4024, 1643,    0],\n",
            "        [6574, 1643, 6405,   -1,    0],\n",
            "        [ 662, 1643, 5627,    0,    0],\n",
            "        [4910, 1643, 2211,    0,    0],\n",
            "        [ 910, 5080, 2542,    0,    0],\n",
            "        [1643,  662, 5126,    0,    0],\n",
            "        [1643, 3090, 4455,    0,    0],\n",
            "        [1643, 2724, 4770,    0,    0],\n",
            "        [ 671, 1666,  347,    0,    0],\n",
            "        [6713, 5685,  662,    0,    0],\n",
            "        [6091, 5844, 5685,    0,    0],\n",
            "        [2130,  317, 1352,    0,    0],\n",
            "        [1305, 6705, 5024,    0,    0],\n",
            "        [6469, 2577, 2724,    0,    0],\n",
            "        [6713, 5278,  662,    0,    0],\n",
            "        [1882, 2323, 3016,    0,    0],\n",
            "        [1796, 1643, 3720,    0,    0],\n",
            "        [3417, 2577,   27,    0,    0],\n",
            "        [3658, 5278, 4383,    0,    0],\n",
            "        [ 662, 2323,  662,    0,    0],\n",
            "        [ 372, 6687, 2577,    0,    0],\n",
            "        [1643, 1106, 2724,    0,    0],\n",
            "        [1643, 2323,  111,    0,    0],\n",
            "        [1643, 1643, 3355,    0,    0],\n",
            "        [5685, 5685,  286,    0,    0],\n",
            "        [5844, 1352, 3601,    0,    0],\n",
            "        [  50, 5024,  662,    0,    0],\n",
            "        [3417, 1352, 4910,    0,    0],\n",
            "        [2323, 4477,  111,    0,    0],\n",
            "        [ 957, 5685,   49,    0,    0],\n",
            "        [1819, 5824, 5024,    0,    0],\n",
            "        [ 910, 3720, 4391,    0,    0],\n",
            "        [1643, 1591, 2577,    0,    0],\n",
            "        [1643, 2558, 1563,    0,    0],\n",
            "        [1643, 6260, 4232,    0,    0],\n",
            "        [5685,   -1, 1643,    0,    0],\n",
            "        [5722,    0,   -1,    0,    0],\n",
            "        [4549,    0,    0,    0,    0],\n",
            "        [3480,    0,    0,    0,    0],\n",
            "        [3720,    0,    0,    0,    0],\n",
            "        [5064,    0,    0,    0,    0],\n",
            "        [1451,    0,    0,    0,    0],\n",
            "        [2781,    0,    0,    0,    0],\n",
            "        [4455,    0,    0,    0,    0],\n",
            "        [3720,    0,    0,    0,    0],\n",
            "        [3206,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [ 995,    0,    0,    0,    0],\n",
            "        [ 286,    0,    0,    0,    0],\n",
            "        [1905,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [ 111,    0,    0,    0,    0],\n",
            "        [ 286,    0,    0,    0,    0],\n",
            "        [1905,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [5222,    0,    0,    0,    0],\n",
            "        [ 910,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [5685,    0,    0,    0,    0],\n",
            "        [1240,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [2577,    0,    0,    0,    0],\n",
            "        [2724,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [4707,    0,    0,    0,    0],\n",
            "        [6659,    0,    0,    0,    0],\n",
            "        [4034,    0,    0,    0,    0],\n",
            "        [4314,    0,    0,    0,    0],\n",
            "        [3480,    0,    0,    0,    0],\n",
            "        [6713,    0,    0,    0,    0],\n",
            "        [ 932,    0,    0,    0,    0],\n",
            "        [6469,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [4910,    0,    0,    0,    0],\n",
            "        [5685,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [5685,    0,    0,    0,    0],\n",
            "        [1240,    0,    0,    0,    0],\n",
            "        [ 762,    0,    0,    0,    0],\n",
            "        [3565,    0,    0,    0,    0],\n",
            "        [6469,    0,    0,    0,    0],\n",
            "        [ 910,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [3146,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [3943,    0,    0,    0,    0],\n",
            "        [5685,    0,    0,    0,    0],\n",
            "        [5824,    0,    0,    0,    0],\n",
            "        [ 910,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [3720,    0,    0,    0,    0],\n",
            "        [6720,    0,    0,    0,    0],\n",
            "        [3003,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [ 910,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [ 995,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [2577,    0,    0,    0,    0],\n",
            "        [2724,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [4170,    0,    0,    0,    0],\n",
            "        [5024,    0,    0,    0,    0],\n",
            "        [5131,    0,    0,    0,    0],\n",
            "        [ 250,    0,    0,    0,    0],\n",
            "        [5762,    0,    0,    0,    0],\n",
            "        [4910,    0,    0,    0,    0],\n",
            "        [  44,    0,    0,    0,    0],\n",
            "        [2164,    0,    0,    0,    0],\n",
            "        [5685,    0,    0,    0,    0],\n",
            "        [1352,    0,    0,    0,    0],\n",
            "        [5024,    0,    0,    0,    0],\n",
            "        [4460,    0,    0,    0,    0],\n",
            "        [2863,    0,    0,    0,    0],\n",
            "        [ 662,    0,    0,    0,    0],\n",
            "        [ 615,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [ 372,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [1819,    0,    0,    0,    0],\n",
            "        [  49,    0,    0,    0,    0],\n",
            "        [6202,    0,    0,    0,    0],\n",
            "        [4250,    0,    0,    0,    0],\n",
            "        [6260,    0,    0,    0,    0],\n",
            "        [2639,    0,    0,    0,    0],\n",
            "        [6260,    0,    0,    0,    0],\n",
            "        [6659,    0,    0,    0,    0],\n",
            "        [4170,    0,    0,    0,    0],\n",
            "        [5024,    0,    0,    0,    0],\n",
            "        [4033,    0,    0,    0,    0],\n",
            "        [1632,    0,    0,    0,    0],\n",
            "        [1643,    0,    0,    0,    0],\n",
            "        [  -1,    0,    0,    0,    0]])\n",
            "lengths: tensor([168,  53,  54,  19,  13])\n",
            "target_variable: tensor([[2639, 1643, 2374,  645, 5199],\n",
            "        [6260, 1643,  662,  662, 6260],\n",
            "        [2639, 1643, 2577, 1402, 2618],\n",
            "        [6260,   37, 2724, 5685, 6311],\n",
            "        [6659, 1643,  111, 5350, 1761],\n",
            "        [4170, 1643, 3355, 3720, 1643],\n",
            "        [5024, 1643,  286,  662,   49],\n",
            "        [4033, 1643, 3601, 3814, 5024],\n",
            "        [1632,   37,  662,  662, 2618],\n",
            "        [1643, 1643, 4910, 3814, 6705],\n",
            "        [  -1, 4326,  111, 1883,   -1],\n",
            "        [   0, 1636,   49,  662,    0],\n",
            "        [   0, 1643, 5024, 6469,    0],\n",
            "        [   0, 1643, 4391, 3720,    0],\n",
            "        [   0, 1643, 2577, 1590,    0],\n",
            "        [   0, 5080, 1563, 1643,    0],\n",
            "        [   0,  662, 4232,   -1,    0],\n",
            "        [   0, 3090, 1643,    0,    0],\n",
            "        [   0, 2724,   -1,    0,    0],\n",
            "        [   0, 1666,    0,    0,    0],\n",
            "        [   0, 5685,    0,    0,    0],\n",
            "        [   0, 5844,    0,    0,    0],\n",
            "        [   0,  317,    0,    0,    0],\n",
            "        [   0, 6705,    0,    0,    0],\n",
            "        [   0, 2577,    0,    0,    0],\n",
            "        [   0, 5278,    0,    0,    0],\n",
            "        [   0, 2323,    0,    0,    0],\n",
            "        [   0, 1643,    0,    0,    0],\n",
            "        [   0, 2577,    0,    0,    0],\n",
            "        [   0, 5278,    0,    0,    0],\n",
            "        [   0, 2323,    0,    0,    0],\n",
            "        [   0, 6687,    0,    0,    0],\n",
            "        [   0, 1106,    0,    0,    0],\n",
            "        [   0, 2323,    0,    0,    0],\n",
            "        [   0, 1643,    0,    0,    0],\n",
            "        [   0, 5685,    0,    0,    0],\n",
            "        [   0, 1352,    0,    0,    0],\n",
            "        [   0, 5024,    0,    0,    0],\n",
            "        [   0, 1352,    0,    0,    0],\n",
            "        [   0, 4477,    0,    0,    0],\n",
            "        [   0, 5685,    0,    0,    0],\n",
            "        [   0, 5824,    0,    0,    0],\n",
            "        [   0, 3720,    0,    0,    0],\n",
            "        [   0, 1591,    0,    0,    0],\n",
            "        [   0, 2558,    0,    0,    0],\n",
            "        [   0, 6260,    0,    0,    0],\n",
            "        [   0,   -1,    0,    0,    0]])\n",
            "mask: tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 1, 0],\n",
            "        [0, 1, 1, 0, 0],\n",
            "        [0, 1, 1, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0]], dtype=torch.uint8)\n",
            "max_target_len: 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP37c9qWd7_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlzHGZ30-zlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #from pytorch\n",
        "# import torch\n",
        "# from torch.jit import script, trace\n",
        "# import torch.nn as nn\n",
        "# from torch import optim\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class EncoderRNN(nn.Module):\n",
        "#     def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "#         super(EncoderRNN, self).__init__()\n",
        "#         self.n_layers = n_layers\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.embedding = embedding\n",
        "\n",
        "#         # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "#         #   because our input size is a word embedding with number of features == hidden_size\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "#                           dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "#     def forward(self, input_seq, input_lengths, hidden=None):\n",
        "#         # Convert word indexes to embeddings\n",
        "#         embedded = self.embedding(input_seq)\n",
        "#         # Pack padded batch of sequences for RNN module\n",
        "#         packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "#         # Forward pass through GRU\n",
        "#         outputs, hidden = self.gru(packed, hidden)\n",
        "#         # Unpack padding\n",
        "#         outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "#         # Sum bidirectional GRU outputs\n",
        "#         outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "#         # Return output and final hidden state\n",
        "#         return outputs, hidden\n",
        "    \n",
        "# class Attn(nn.Module):\n",
        "#     def __init__(self, method, hidden_size):\n",
        "#         super(Attn, self).__init__()\n",
        "#         self.method = method\n",
        "#         if self.method not in ['dot', 'general', 'concat']:\n",
        "#             raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "#         self.hidden_size = hidden_size\n",
        "#         if self.method == 'general':\n",
        "#             self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "#         elif self.method == 'concat':\n",
        "#             self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "#             self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "#     def dot_score(self, hidden, encoder_output):\n",
        "#         return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "#     def general_score(self, hidden, encoder_output):\n",
        "#         energy = self.attn(encoder_output)\n",
        "#         return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "#     def concat_score(self, hidden, encoder_output):\n",
        "#         energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "#         return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "#     def forward(self, hidden, encoder_outputs):\n",
        "#         # Calculate the attention weights (energies) based on the given method\n",
        "#         if self.method == 'general':\n",
        "#             attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "#         elif self.method == 'concat':\n",
        "#             attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "#         elif self.method == 'dot':\n",
        "#             attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "#         # Transpose max_length and batch_size dimensions\n",
        "#         attn_energies = attn_energies.t()\n",
        "\n",
        "#         # Return the softmax normalized probability scores (with added dimension)\n",
        "#         return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
        "# class LuongAttnDecoderRNN(nn.Module):\n",
        "#     def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "#         super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "#         # Keep for reference\n",
        "#         self.attn_model = attn_model\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.output_size = output_size\n",
        "#         self.n_layers = n_layers\n",
        "#         self.dropout = dropout\n",
        "\n",
        "#         # Define layers\n",
        "#         self.embedding = embedding\n",
        "#         self.embedding_dropout = nn.Dropout(dropout)\n",
        "#         self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "#         self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "#         self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#         self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "#     def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "#         # Note: we run this one step (word) at a time\n",
        "#         # Get embedding of current input word\n",
        "#         embedded = self.embedding(input_step)\n",
        "#         embedded = self.embedding_dropout(embedded)\n",
        "#         # Forward through unidirectional GRU\n",
        "#         rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "#         # Calculate attention weights from the current GRU output\n",
        "#         attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "#         # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "#         context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "#         # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "#         rnn_output = rnn_output.squeeze(0)\n",
        "#         context = context.squeeze(1)\n",
        "#         concat_input = torch.cat((rnn_output, context), 1)\n",
        "#         concat_output = torch.tanh(self.concat(concat_input))\n",
        "#         # Predict next word using Luong eq. 6\n",
        "#         output = self.out(concat_output)\n",
        "#         output = F.softmax(output, dim=1)\n",
        "#         # Return output and final hidden state\n",
        "#         return output, hidden\n",
        "    \n",
        "# def maskNLLLoss(inp, target, mask):\n",
        "#     nTotal = mask.sum()\n",
        "#     crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "#     loss = crossEntropy.masked_select(mask).mean()\n",
        "#     loss = loss.to(device)\n",
        "#     return loss, nTotal.item()\n",
        "\n",
        "# MAX_LENGTH = 15\n",
        "# def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "#           encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "#     # Zero gradients\n",
        "#     encoder_optimizer.zero_grad()\n",
        "#     decoder_optimizer.zero_grad()\n",
        "#     # Set device options\n",
        "#     input_variable = input_variable\n",
        "#     lengths = lengths\n",
        "#     target_variable = target_variable\n",
        "#     mask = mask\n",
        "#     # Initialize variables\n",
        "#     loss = 0\n",
        "#     print_losses = []\n",
        "#     n_totals = 0\n",
        "#     # Forward pass through encoder\n",
        "#     encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "#     # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "#     decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "#     decoder_input = decoder_input.to(device)\n",
        "#     # Set initial decoder hidden state to the encoder's final hidden state\n",
        "#     decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "#     # Determine if we are using teacher forcing this iteration\n",
        "#     use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "#     # Forward batch of sequences through decoder one time step at a time\n",
        "#     if use_teacher_forcing:\n",
        "#         for t in range(max_target_len):\n",
        "#             decoder_output, decoder_hidden = decoder(\n",
        "#                 decoder_input, decoder_hidden, encoder_outputs\n",
        "#             )\n",
        "#             # Teacher forcing: next input is current target\n",
        "#             decoder_input = target_variable[t].view(1, -1)\n",
        "#             # Calculate and accumulate loss\n",
        "#             mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "#             loss += mask_loss\n",
        "#             print_losses.append(mask_loss.item() * nTotal)\n",
        "#             n_totals += nTotal\n",
        "#     else:\n",
        "#         for t in range(max_target_len):\n",
        "#             decoder_output, decoder_hidden = decoder(\n",
        "#                 decoder_input, decoder_hidden, encoder_outputs\n",
        "#             )\n",
        "#             # No teacher forcing: next input is decoder's own current output\n",
        "#             _, topi = decoder_output.topk(1)\n",
        "#             decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "#             decoder_input = decoder_input\n",
        "#             # Calculate and accumulate loss\n",
        "#             mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "#             loss += mask_loss\n",
        "#             print_losses.append(mask_loss.item() * nTotal)\n",
        "#             n_totals += nTotal\n",
        "\n",
        "#     # Perform backpropatation\n",
        "#     loss.backward()\n",
        "#     # Clip gradients: gradients are modified in place\n",
        "#     _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "#     _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "#     # Adjust model weights\n",
        "#     encoder_optimizer.step()\n",
        "#     decoder_optimizer.step()\n",
        "\n",
        "#     return sum(print_losses) / n_totals\n",
        "\n",
        "# def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
        "\n",
        "#     # Load batches for each iteration\n",
        "#     training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "#                       for _ in range(n_iteration)]\n",
        "\n",
        "#     # Initializations\n",
        "#     print('Initializing ...')\n",
        "#     start_iteration = 1\n",
        "#     print_loss = 0\n",
        "#     if loadFilename:\n",
        "#         start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "#     # Training loop\n",
        "#     print(\"Training...\")\n",
        "#     for iteration in range(start_iteration, n_iteration + 1):\n",
        "#         training_batch = training_batches[iteration - 1]\n",
        "#         # Extract fields from batch\n",
        "#         input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "        \n",
        "#         # Run a training iteration with batch\n",
        "#         loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "#                      decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "#         print_loss += loss\n",
        "\n",
        "#         # Print progress\n",
        "#         if iteration % print_every == 0:\n",
        "#             print_loss_avg = print_loss / print_every\n",
        "#             print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "#             print_loss = 0\n",
        "\n",
        "#         # Save checkpoint\n",
        "#         if (iteration % save_every == 0):\n",
        "#             directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "#             if not os.path.exists(directory):\n",
        "#                 os.makedirs(directory)\n",
        "#             torch.save({\n",
        "#                 'iteration': iteration,\n",
        "#                 'en': encoder.state_dict(),\n",
        "#                 'de': decoder.state_dict(),\n",
        "#                 'en_opt': encoder_optimizer.state_dict(),\n",
        "#                 'de_opt': decoder_optimizer.state_dict(),\n",
        "#                 'loss': loss,\n",
        "#                 'voc_dict': voc.__dict__,\n",
        "#                 'embedding': embedding.state_dict()\n",
        "#             }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n",
        "        \n",
        "# class GreedySearchDecoder(nn.Module):\n",
        "#     def __init__(self, encoder, decoder):\n",
        "#         super(GreedySearchDecoder, self).__init__()\n",
        "#         self.encoder = encoder\n",
        "#         self.decoder = decoder\n",
        "\n",
        "#     def forward(self, input_seq, input_length, max_length):\n",
        "#         # Forward input through encoder model\n",
        "#         encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "#         # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "#         decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "#         # Initialize decoder input with SOS_token\n",
        "#         decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "#         # Initialize tensors to append decoded words to\n",
        "#         all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "#         all_scores = torch.zeros([0], device=device)\n",
        "#         # Iteratively decode one word token at a time\n",
        "#         for _ in range(max_length):\n",
        "#             # Forward pass through decoder\n",
        "#             decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "#             # Obtain most likely word token and its softmax score\n",
        "#             decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "#             # Record token and score\n",
        "#             all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "#             all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "#             # Prepare current token to be next decoder input (add a dimension)\n",
        "#             decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "#         # Return collections of word tokens and scores\n",
        "#         return all_tokens, all_scores\n",
        "    \n",
        "# def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "#     ### Format input sentence as a batch\n",
        "#     # words -> indexes\n",
        "#     indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "#     # Create lengths tensor\n",
        "#     lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "#     # Transpose dimensions of batch to match models' expectations\n",
        "#     input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "#     # Use appropriate device\n",
        "#     input_batch = input_batch.to(device)\n",
        "#     lengths = lengths.to(device)\n",
        "#     # Decode sentence with searcher\n",
        "#     tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "#     # indexes -> words\n",
        "#     decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "#     return decoded_words\n",
        "\n",
        "\n",
        "# def evaluateInput(encoder, decoder, searcher, voc):\n",
        "#     input_sentence = ''\n",
        "#     while(1):\n",
        "#         try:\n",
        "#             # Get input sentence\n",
        "#             input_sentence = input('> ')\n",
        "#             # Check if it is quit case\n",
        "#             if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "#             # Normalize sentence\n",
        "#             input_sentence = normalizeString(input_sentence)\n",
        "#             # Evaluate sentence\n",
        "#             output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "#             # Format and print response sentence\n",
        "#             output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "#             print('Bot:', ' '.join(output_words))\n",
        "\n",
        "#         except KeyError:\n",
        "#             print(\"Error: Encountered unknown word.\")\n",
        "            \n",
        "\n",
        "\n",
        "# # Configure models\n",
        "# model_name = 'cb_model'\n",
        "# attn_model = 'dot'\n",
        "# #attn_model = 'general'\n",
        "# #attn_model = 'concat'\n",
        "# hidden_size = 500\n",
        "# encoder_n_layers = 2\n",
        "# decoder_n_layers = 2\n",
        "# dropout = 0.1\n",
        "# batch_size = 64\n",
        "\n",
        "# # Set checkpoint to load from; set to None if starting from scratch\n",
        "# loadFilename = None\n",
        "# checkpoint_iter = 4000\n",
        "# #loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "# #                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "# #                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "\n",
        "# # Load model if a loadFilename is provided\n",
        "# if loadFilename:\n",
        "#     # If loading on same machine the model was trained on\n",
        "#     checkpoint = torch.load(loadFilename)\n",
        "#     # If loading a model trained on GPU to CPU\n",
        "#     #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "#     encoder_sd = checkpoint['en']\n",
        "#     decoder_sd = checkpoint['de']\n",
        "#     encoder_optimizer_sd = checkpoint['en_opt']\n",
        "#     decoder_optimizer_sd = checkpoint['de_opt']\n",
        "#     embedding_sd = checkpoint['embedding']\n",
        "#     voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "# print('Building encoder and decoder ...')\n",
        "# # Initialize word embeddings\n",
        "# embedding = nn.Embedding(len(word2index), hidden_size)\n",
        "# if loadFilename:\n",
        "#     embedding.load_state_dict(embedding_sd)\n",
        "# # Initialize encoder & decoder models\n",
        "# encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "# decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, len(word2index), decoder_n_layers, dropout)\n",
        "# if loadFilename:\n",
        "#     encoder.load_state_dict(encoder_sd)\n",
        "#     decoder.load_state_dict(decoder_sd)\n",
        "# # Use appropriate device\n",
        "# encoder = encoder\n",
        "# decoder = decoder\n",
        "# print('Models built and ready to go!')\n",
        "\n",
        "\n",
        "# import os\n",
        "# # Configure training/optimization\n",
        "# clip = 50.0\n",
        "# teacher_forcing_ratio = 1.0\n",
        "# learning_rate = 0.0001\n",
        "# decoder_learning_ratio = 5.0\n",
        "# n_iteration = 4000\n",
        "# print_every = 1\n",
        "# save_every = 500\n",
        "# save_dir = os.path.join(\"data\", \"save\")\n",
        "# # Ensure dropout layers are in train mode\n",
        "# encoder.train()\n",
        "# decoder.train()\n",
        "\n",
        "# # Initialize optimizers\n",
        "# print('Building optimizers ...')\n",
        "# encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "# decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "# if loadFilename:\n",
        "#     encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "#     decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "# # Run training iterations\n",
        "# corpus_name = 'data'\n",
        "# loadFilename = False\n",
        "# print(\"Starting Training!\")\n",
        "# trainIters(model_name, word2index, chat_pair, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "#            embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "#            print_every, save_every, clip, corpus_name, loadFilename)\n",
        "\n",
        "# # Set dropout layers to eval mode\n",
        "# encoder.eval()\n",
        "# decoder.eval()\n",
        "\n",
        "# # Initialize search module\n",
        "# searcher = GreedySearchDecoder(encoder, decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztn1SfAaN0U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7Q73flEOBGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKp0NwPuOFVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRUyMU-GOLMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go67AZTPP9vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm9rVc4YmMOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKei5JodOVg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nusX58rnOWnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhJYWrWoTSdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}